# Siamese Nueral Network For Near Duplicate Detection in Web App Model Inference

## ğŸ› ï¸ Prerequisites

## ğŸš€ Get Started

Follow these steps to create and activate the Conda environment to set up the project.


### 1) Clone the repository

```bash
git clone https://github.com/ast-fortiss-tum/near-duplicate-detection-siamese-networks.git
cd near-duplicate-detection-siamese-networks
```

### 2) Create the Conda environment

The `environment.yml` already pins compatible versions (PythonÂ 3.11, NumPyÂ <Â 2, SciPyÂ 1.10.1, etc.) and contains the line `- -e .` so your code is installed automatically.

```bash
conda env create --name snn-ndd -f environment.yml
```

*What this does*

1. Creates a new Conda env called **`snn-ndd`**.
2. Installs all Condaâ€‘managed packages (PyTorch, transformers, gensim, â€¦).
3. Runs `pip install -e .` inside the env, wiring up your local source tree as a package named **`ndd`**.

### 3) Activate the environment

```bash
conda activate snn-ndd
```


## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ resources/                # Downloaded baseline datasets, doms, baseline runners (jar) and doc2vec embedding models
â”œâ”€â”€ scripts/                  # Python scripts for running evaluations
â”‚   â”œâ”€â”€ rq1/
â”‚   â”‚   â”œâ”€â”€ within-app-classification/
â”‚   â”‚   â”‚   â”œâ”€â”€ bert_contrastive_classification.py
â”‚   â”‚   â”‚   â”œâ”€â”€ doc2vec_contrastive_classification.py
â”‚   â”‚   â”‚   â””â”€â”€ markuplm_contrastive_classification.py
â”‚   â”‚   â”œâ”€â”€ across-app-classification/
â”‚   â”‚   â”‚   â””â”€â”€ [...same naming as above...]
â”‚   â”‚   â””â”€â”€ baseline-classification/
â”‚   â”‚       â””â”€â”€ run_baseline.py
â”‚   â”œâ”€â”€ rq2/                   # RQ2 evaluation scripts
â”‚   â”œâ”€â”€ rq3/                   # RQ3 evaluation scripts
â”‚   â””â”€â”€ rq4/                   # RQ4 evaluation scripts
â”œâ”€â”€ results/                  # Generated experiment results
â”‚   â”œâ”€â”€ rq1/
â”‚   â”œâ”€â”€ rq2/
â”‚   â”œâ”€â”€ rq3/
â”‚   â””â”€â”€ rq4/
â”œâ”€â”€ baseline/                 # Baseline results
â”œâ”€â”€ models/                   # Saved trained models
â”œâ”€â”€ embedding/                # Cached embedding files
â””â”€â”€ README.md                 
```


## ğŸ–¥ï¸ Generate Reported Results


### 1) RQ1: Near-Duplicate Detection

#### a) SNN Evaluation

1. **Download resources**
   Get `resources.zip` from:

   ```
   https://syncandshare.lrz.de/getlink/fiY4KcSXCwSLW8g8TVmnep/resources.zip
   ```

   *Password: `snn-ndd`*

2. **Unpack and move the resources folder to the base project**

   ```bash
   unzip resources.zip -d resources
   ```

   You should now have folders:

   ```
   dataset
   scripts
   resources/
   â”œâ”€â”€ baseline-dataset/
   â”œâ”€â”€ baseline-runner/
   â”œâ”€â”€ doms/
   â””â”€â”€ embedding-models/
   ```

3. **Run the evaluation**

   ```bash
   python scripts/rq1/<evaluation_setting>-app-classification/<embedding_type>_contrastive_classification.py
   ```

   * `<evaluation_setting>`:

     * `within`
     * `across`
   * `<embedding_type>`:

     * `bert` (select or adjust the variant inside the script)
     * `doc2vec`
     * `markuplm`

4. **Outputs**

   * Experiment results â†’ `results/rq1/`
   * Trained models â†’ `models/`
   * Cached embeddings â†’ `embedding/`

> **Re-runs** will automatically reuse any existing models or embeddings; nothing is re-trained if already present.




## âš™ï¸ Run New Experiment
